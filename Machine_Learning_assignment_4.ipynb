{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1. What are the key tasks involved in getting ready to work with machine learning modeling?\n",
        "\n",
        "Answer:- Problem Definition:\n",
        "Clearly define the problem you intend to solve with machine learning. Specify the task (classification, regression, clustering, etc.), the goals, and the desired outcomes.\n",
        "\n",
        "Data Collection:\n",
        "Gather relevant data that will be used for training and evaluating the machine learning model. Ensure the data is representative of the real-world scenarios the model will encounter.\n",
        "\n",
        "Data Preprocessing:\n",
        "Clean and prepare the data for analysis. This involves handling missing values, dealing with outliers, encoding categorical variables, and normalizing or scaling numerical features.\n",
        "\n",
        "Exploratory Data Analysis (EDA):\n",
        "Conduct EDA to gain insights into the data. Visualize distributions, correlations, and patterns in the data to inform feature selection and model choices.\n",
        "\n",
        "Feature Engineering:\n",
        "Select, create, or transform features that are relevant to the problem. Feature engineering can significantly impact the model's performance.\n",
        "\n",
        "Data Splitting:\n",
        "Divide the data into training, validation, and testing sets. The training set is used to train the model, the validation set helps tune hyperparameters, and the testing set evaluates the final model's performance.\n",
        "\n",
        "Model Selection:\n",
        "Choose appropriate machine learning algorithms or models based on the problem type, data characteristics, and desired outcomes. Consider factors like interpretability, complexity, and performance.\n",
        "\n",
        "Hyperparameter Tuning:\n",
        "Fine-tune hyperparameters to optimize the model's performance. Hyperparameters control aspects of the model that are not learned during training, such as learning rate or regularization strength.\n",
        "\n",
        "Model Training:\n",
        "Train the selected model on the training data using appropriate algorithms and techniques. This involves adjusting model parameters to minimize the chosen loss function.\n",
        "\n",
        "Model Evaluation:\n",
        "Assess the model's performance using evaluation metrics specific to the task, such as accuracy, precision, recall, mean squared error, etc. Evaluate the model on both the validation and testing sets.\n",
        "\n",
        "Model Interpretability:\n",
        "For some applications, it's important to understand how the model makes decisions. Techniques like feature importance analysis and visualization can help interpret model predictions.\n",
        "\n",
        "Model Deployment:\n",
        "Deploy the trained model into a production environment where it can make predictions on new, unseen data. This involves ensuring the model's integration with the system and addressing issues like scalability and latency.\n",
        "\n",
        "Monitoring and Maintenance:\n",
        "Continuously monitor the model's performance in the real-world setting. Update and retrain the model as necessary to maintain accuracy and adapt to changing data distributions.\n",
        "\n",
        "Ethical Considerations:\n",
        "Consider potential ethical concerns related to data privacy, fairness, bias, and potential societal impacts of the model's predictions."
      ],
      "metadata": {
        "id": "z8nysgrp9TXl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jIciB439DzPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2. What are the different forms of data used in machine learning? Give a specific example for each of\n",
        "them.\n",
        "\n",
        "Answer:- Numerical Data (Quantitative Data):\n",
        "Numerical data consists of quantitative values that can be measured and expressed as numbers. This type of data is commonly used in machine learning for both input features and target variables.\n",
        "\n",
        "Example: House Price Prediction\n",
        "In the context of predicting house prices, numerical data includes features like square footage, number of bedrooms, and bathrooms. The target variable (price) is also a numerical value. For instance, a house with 2000 square feet, 3 bedrooms, and 2 bathrooms might be represented as (2000, 3, 2) with a price label of $300,000.\n",
        "\n",
        "Categorical Data (Qualitative Data):\n",
        "Categorical data represents distinct categories or labels that don't have a numerical relationship between them. This type of data is often used to represent attributes with specific classes.\n",
        "\n",
        "Example: Customer Segmentation\n",
        "In a customer segmentation task, categorical data could include attributes like gender, marital status, and education level. Each of these attributes has discrete categories like \"male\" or \"female,\" \"married\" or \"single,\" and \"high school,\" \"bachelor's,\" \"master's,\" etc."
      ],
      "metadata": {
        "id": "fCywzzaLD2YC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zt98DvZzEMbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question:- 3. Distinguish:\n",
        "\n",
        "1. Numeric vs. categorical attributes\n",
        "\n",
        "2. Feature selection vs. dimensionality reduction\n",
        "\n",
        "Answer:- Numeric vs. categorical attributes\n",
        "\n",
        "Numeric Attributes:\n",
        "\n",
        "Numeric attributes represent quantitative values that can be measured and expressed as numbers.\n",
        "They are continuous and can take a wide range of values.\n",
        "Numeric attributes are used for tasks like regression, where the goal is to predict a continuous value.\n",
        "Statistical operations like mean, median, and standard deviation make sense for numeric attributes.\n",
        "Example:\n",
        "Suppose you are analyzing data about houses for predicting their prices. Numeric attributes could include features like square footage, number of bedrooms, and bathrooms. These attributes are measurable and can take various numerical values.\n",
        "\n",
        "Categorical Attributes:\n",
        "\n",
        "Categorical attributes represent distinct categories or labels that don't have a numerical relationship between them.\n",
        "They are often used for classification tasks, where the goal is to assign data points to predefined categories or classes.\n",
        "Categorical attributes can be nominal (no inherent order) or ordinal (have a meaningful order/rank).\n",
        "Example:\n",
        "In the context of customer segmentation, categorical attributes could include gender, marital status, and education level. Each of these attributes has discrete categories like \"male\" or \"female,\" \"married\" or \"single,\" and \"high school,\" \"bachelor's,\" \"master's,\" etc\n",
        "\n",
        "\n",
        "2. Feature selection vs. dimensionality reduction\n",
        "\n",
        ":- Feature Selection:\n",
        "\n",
        "Feature selection involves choosing a subset of relevant features from the original set of features to use for model training.\n",
        "The goal is to retain the most informative and significant features while discarding irrelevant or redundant ones.\n",
        "\n",
        ":- Dimensionality Reduction:\n",
        "\n",
        "Dimensionality reduction involves transforming the original features into a lower-dimensional space while preserving the most important information.\n",
        "The goal is to reduce the complexity of the dataset, overcome multicollinearity, and prevent overfitting.\n",
        "Dimensionality reduction techniques create new features that are combinations of the original ones (principal components, latent factors, etc.)."
      ],
      "metadata": {
        "id": "jafxM__SEP76"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JJyAHPSoEtmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Make quick notes on any two of the following:\n",
        "\n",
        "1. The histogram\n",
        "\n",
        "2. Use a scatter plot\n",
        "\n",
        "3.PCA (Personal Computer Aid)\n",
        "\n",
        "Answer:- The Histogram\n",
        "\n",
        "The histogram is a graphical representation of the distribution of a dataset. It provides insights into the frequency or count of data points falling into different intervals or \"bins.\" Histograms are commonly used for understanding the underlying distribution of a continuous variable and identifying patterns, trends, and outliers in the data.\n",
        "\n",
        ":- Use a scatter plot\n",
        "\n",
        "A scatter plot is a graphical representation of data points in a two-dimensional space. It's especially useful for visualizing the relationship between two numeric variables. Each data point is represented as a dot on the plot, with its position determined by the values of the two variables.\n",
        "\n",
        "Key Features of a Scatter Plot:\n",
        "\n",
        "X-axis: Represents one variable.\n",
        "Y-axis: Represents the other variable.\n",
        "Data Points: Each data point is plotted as a dot on the graph.\n"
      ],
      "metadata": {
        "id": "orjUbM20EzCK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AYx1bVyFFMS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5. Why is it necessary to investigate data? Is there a discrepancy in how qualitative and quantitative\n",
        "data are explored?\n",
        "\n",
        "Answer:- Qualitative Data:\n",
        "\n",
        "Qualitative data, such as text or categorical attributes, require different techniques for exploration.\n",
        "Methods like text analysis, sentiment analysis, and content coding are used to extract insights from textual data.\n",
        "Visualization techniques for qualitative data might include word clouds, bar charts for categorical data distribution, and thematic analysis.\n",
        "Quantitative Data:\n",
        "\n",
        "Quantitative data, including numerical attributes, are often explored through statistical analysis and visualization.\n",
        "Techniques like histograms, scatter plots, correlation matrices, and regression analysis are commonly used for numeric data exploration."
      ],
      "metadata": {
        "id": "TtqJAKrNJJ3l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gONMRD9gJWbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6. What are the various histogram shapes? What exactly are ‘bins&#39;?\n",
        "\n",
        "Answer:- Normal Distribution (Bell Curve):\n",
        "\n",
        "A symmetrical distribution with a single peak in the center.\n",
        "Mean, median, and mode are all located at the center of the distribution.\n",
        "Commonly found in natural phenomena and is a basis for many statistical methods.\n",
        "Skewed to the Right (Positively Skewed):\n",
        "\n",
        "The tail of the distribution extends towards the right (larger values).\n",
        "Mean > Median > Mode.\n",
        "Occurs when a few high values push the mean upward.\n",
        "Skewed to the Left (Negatively Skewed):\n",
        "\n",
        "The tail of the distribution extends towards the left (smaller values).\n",
        "Mode > Median > Mean.\n",
        "Occurs when a few low values pull the mean downward.\n",
        "Bimodal Distribution:\n",
        "\n",
        "Has two distinct peaks, indicating the presence of two different groups or populations within the data.\n",
        "Each peak might represent different behaviors, attributes, or phenomena.\n",
        "Uniform Distribution:\n",
        "\n",
        "All values have approximately the same frequency, resulting in a flat histogram.\n",
        "No particular value is more frequent than others.\n",
        "Multimodal Distribution:\n",
        "\n",
        "Has more than two peaks, indicating the presence of multiple modes or subpopulations within the data.\n",
        "Each peak might represent a distinct behavior or phenomenon."
      ],
      "metadata": {
        "id": "5HujG3FOJaqw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2otWcmo3Jpou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7. How do we deal with data outliers?\n",
        "\n",
        "Answer:- Dealing with data outliers is an important step in data preprocessing to ensure that outliers do not disproportionately influence the analysis or modeling process. Outliers are data points that significantly deviate from the rest of the dataset, and they can arise due to various reasons, such as measurement errors, data entry mistakes, or rare events. Handling outliers depends on the specific context and the goals of the analysis. Here are some approaches to deal with data outliers:\n",
        "\n",
        "Identify Outliers:\n",
        "Start by identifying and detecting outliers in the dataset. Visualization techniques like box plots, scatter plots, and histograms can help identify data points that fall far outside the normal range."
      ],
      "metadata": {
        "id": "nbqlQ-FnJrsS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvOgmhofJ2Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8. What are the various central inclination measures? Why does mean vary too much from median in\n",
        "certain data sets?\n",
        "\n",
        "Answer:- Central tendency measures are statistical measures that provide information about the center or typical value of a dataset. They help summarize the distribution of data and give insight into where most of the data points cluster. There are several central inclination measures, with the mean and median being the most common ones. The most commonly used central tendency measures are:\n",
        "\n",
        "Mean (Average):\n",
        "\n",
        "The mean is calculated by summing up all the values in the dataset and then dividing by the total number of values.\n",
        "It's sensitive to outliers, as extreme values can significantly impact the mean.\n",
        "Mathematically:\n",
        "Mean\n",
        "=\n",
        "∑\n",
        "values\n",
        "number of values\n",
        "Mean=\n",
        "number of values\n",
        "∑values\n",
        "​\n",
        "\n",
        "Median:\n",
        "\n",
        "The median is the middle value in a sorted dataset. If there's an even number of values, the median is the average of the two middle values.\n",
        "It's robust to outliers, as it's not influenced by extreme values.\n",
        "Mathematically: Arrange values in ascending order and find the middle value.\n",
        "Mode:\n",
        "\n",
        "The mode is the value that appears most frequently in the dataset.\n",
        "A dataset can have one mode (unimodal), two modes (bimodal), or more (multimodal)."
      ],
      "metadata": {
        "id": "L3zuhGEdJ38Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7iRpfIXZKATW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}